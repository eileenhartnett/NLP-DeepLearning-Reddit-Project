{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import zeros\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import multiprocessing\n",
    "\n",
    "# Train, test, split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For handling imbalanced classes\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Word2Vec\n",
    "import gensim \n",
    "import gensim.models\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = pd.read_csv('../data/posts-preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>timeframe</th>\n",
       "      <th>text</th>\n",
       "      <th>datetime</th>\n",
       "      <th>words</th>\n",
       "      <th>word_stems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sub21036</td>\n",
       "      <td>bulimia</td>\n",
       "      <td>pre-covid</td>\n",
       "      <td>['how can i stop hating myself  i have been on...</td>\n",
       "      <td>2017-12-02 16:36:16</td>\n",
       "      <td>['[', \"'how\", 'stop', 'hating', 'eating', 'dis...</td>\n",
       "      <td>['[', \"'how\", 'stop', 'hating', 'eating', 'dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>sub12048</td>\n",
       "      <td>bulimia</td>\n",
       "      <td>pre-covid</td>\n",
       "      <td>['new guy here 1 month on it 16m  hi guys just...</td>\n",
       "      <td>2017-12-05 19:45:25</td>\n",
       "      <td>['[', \"'new\", 'guy', '1', 'month', '16m', 'hi'...</td>\n",
       "      <td>['[', \"'new\", 'guy', '1', 'month', '16m', 'hi'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>sub6523</td>\n",
       "      <td>bulimia</td>\n",
       "      <td>pre-covid</td>\n",
       "      <td>['so i just vomited blood what can i eat while...</td>\n",
       "      <td>2017-12-06 16:58:16</td>\n",
       "      <td>['[', \"'so\", 'vomited', 'blood', 'eat', 'throa...</td>\n",
       "      <td>['[', \"'so\", 'vomited', 'blood', 'eat', 'throa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>sub37858</td>\n",
       "      <td>bulimia</td>\n",
       "      <td>pre-covid</td>\n",
       "      <td>['recovery is expensive  during recovery  hi i...</td>\n",
       "      <td>2017-12-07 14:07:27</td>\n",
       "      <td>['[', \"'recovery\", 'expensive', 'recovery', 'h...</td>\n",
       "      <td>['[', \"'recovery\", 'expensive', 'recovery', 'h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>sub21036</td>\n",
       "      <td>bulimia</td>\n",
       "      <td>pre-covid</td>\n",
       "      <td>['extreme tongue pain  i purged a few nights a...</td>\n",
       "      <td>2017-12-08 20:16:50</td>\n",
       "      <td>['[', \"'extreme\", 'tongue', 'pain', 'purged', ...</td>\n",
       "      <td>['[', \"'extreme\", 'tongue', 'pain', 'purged', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     author subreddit  timeframe  \\\n",
       "0  sub21036   bulimia  pre-covid   \n",
       "1  sub12048   bulimia  pre-covid   \n",
       "2   sub6523   bulimia  pre-covid   \n",
       "3  sub37858   bulimia  pre-covid   \n",
       "4  sub21036   bulimia  pre-covid   \n",
       "\n",
       "                                                text             datetime  \\\n",
       "0  ['how can i stop hating myself  i have been on...  2017-12-02 16:36:16   \n",
       "1  ['new guy here 1 month on it 16m  hi guys just...  2017-12-05 19:45:25   \n",
       "2  ['so i just vomited blood what can i eat while...  2017-12-06 16:58:16   \n",
       "3  ['recovery is expensive  during recovery  hi i...  2017-12-07 14:07:27   \n",
       "4  ['extreme tongue pain  i purged a few nights a...  2017-12-08 20:16:50   \n",
       "\n",
       "                                               words  \\\n",
       "0  ['[', \"'how\", 'stop', 'hating', 'eating', 'dis...   \n",
       "1  ['[', \"'new\", 'guy', '1', 'month', '16m', 'hi'...   \n",
       "2  ['[', \"'so\", 'vomited', 'blood', 'eat', 'throa...   \n",
       "3  ['[', \"'recovery\", 'expensive', 'recovery', 'h...   \n",
       "4  ['[', \"'extreme\", 'tongue', 'pain', 'purged', ...   \n",
       "\n",
       "                                          word_stems  \n",
       "0  ['[', \"'how\", 'stop', 'hating', 'eating', 'dis...  \n",
       "1  ['[', \"'new\", 'guy', '1', 'month', '16m', 'hi'...  \n",
       "2  ['[', \"'so\", 'vomited', 'blood', 'eat', 'throa...  \n",
       "3  ['[', \"'recovery\", 'expensive', 'recovery', 'h...  \n",
       "4  ['[', \"'extreme\", 'tongue', 'pain', 'purged', ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binarize targets using get_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will use each subreddit as target (except mental health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = pd.get_dummies(posts, columns=['subreddit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts.drop(columns='subreddit_mentalhealth', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create Word2Vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **Continuous Bag of Words (CBOW) model**: CBOW model predicts the current word given context words within specific window. The input layer contains the context words and the output layer contains the current word. The hidden layer contains the number of dimensions in which we want to represent current word present at the output layer.\n",
    "\n",
    "https://www.geeksforgeeks.org/python-word-embedding-using-word2vec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many cores am I working with?\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in this computer\n",
    "cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters: \n",
    "- size: (default 100) The number of dimensions of the embedding, e.g. the length of the dense vector to represent each token (word).\n",
    "- window: (default 5) The maximum distance between a target word and words around the target word.\n",
    "- min_count: (default 5) The minimum count of words to consider when training the model; words with an occurrence less than this count will be ignored.\n",
    "- workers: (default 3) The number of threads to use while training.\n",
    "- sg: (default 0 or CBOW) The training algorithm, either CBOW (0) or skip gram (1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code help from:\n",
    "- https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html\n",
    "- https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word2vec algorithm processes documents sentence by sentence. This means we will preserve the sentence-based structure during cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a word2vec model on reddit posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing of sentences using Gensim's pre-processing on posts, so that the input yields one sentence (list of utf8 words) after another. https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        for line in posts['text']:\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = MyCorpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(sentences=sentences, workers=cores-1) # run on all cores minus 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model is fit, we print the size of the learned vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize vocabulary size in model\n",
    "vocab = list(model.wv.vocab)\n",
    "print('Vocabulary size: %d' % len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save the learned embedding vectors to file using the save_word2vec_format() on the model’s ‘wv‘ (word vector) attribute. The embedding is saved in ASCII format with one word and vector per line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'embedding_word2vec.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model in ASCII (word2vec) format\n",
    "model.wv.save_word2vec_format(filename, binary=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
